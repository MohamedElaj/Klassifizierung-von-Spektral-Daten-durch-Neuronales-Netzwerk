# -*- coding: utf-8 -*-
"""Bachelorarbeit_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a6Q4nbXVUpXxnF-qnWFQnV03UEVzLbaR
"""

pip install tensorflow

"""#Erstellung der DataFrames für die Nutzung des Neuronalen Netzwerks."""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from google.colab import files
import tensorflow as tf
from keras.models import Sequential
from keras.layers import GRU, Dense, Activation
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

"""#Datenmanipulation für das Neuronale Netzwerk."""

pfad = "/content/Datensatz1.xlsx"
Datensatz1 = pd.read_excel(pfad)

pfad = "/content/Datensatz3.xlsx"
Datensatz3 = pd.read_excel(pfad)

pfad = "/content/Datensatz4.xlsx"
Datensatz4 = pd.read_excel(pfad)

pfad = "/content/Datensatz5.xlsx"
Datensatz5 = pd.read_excel(pfad)

pfad = "/content/Datensatz6.xlsx"
Datensatz6 = pd.read_excel(pfad)

pfad = "/content/Datensatz_krank.xlsx"
Datensatz_krank = pd.read_excel(pfad)

#Das sind die Ergebnisse die benötigt werden zu jedem Datensatz.
ergebnisse = {
    'Krankheitszustand': [1, 1, 1, 1, 1, 0]
}

labels = pd.DataFrame(ergebnisse)

# Organisieren der Daten und Labels
data_frames = [Datensatz1, Datensatz3, Datensatz4, Datensatz5, Datensatz6, Datensatz_krank]
data_with_labels = []

for i, df in enumerate(data_frames):
    label = labels.loc[i, 'Krankheitszustand']  # Das Label für den aktuellen Datensatz
    data_with_labels.append((df, label))

# Ausgabe der ersten paar Einträge in data_with_labels
for i in range(6):  # Zeige nur die ersten 5 Einträge zur Demonstration
    print("Datensatz {}: Label - {}".format(i+1, data_with_labels[i][1]))
    print(data_with_labels[i][0])
    print()

X_train = np.array([df.values for df, _ in data_with_labels[:5]])  # Extrahieren der Daten aus den DataFrames
X_train = X_train[:, :, :3]   # Die ersten drei Spalten werden extrahiert (Frequenz, Amplitude, Phase)
y_train = np.array([label for _, label in data_with_labels[:5]])  # Extrahieren der Labels
X_test = np.array([Datensatz_krank.values])
X_test = X_test[:, :, :3]
label_entry = labels['Krankheitszustand'].iloc[5]
y_test = np.array(label_entry)

# Netzwerksparameter
input_size = 3
hidden_size = 256
num_layers = 2
num_classes = 1
batch_size = 3
num_epochs = 50
learning_rate = 0.0003
threshold = 0.5

# Modell erstellen
model = Sequential([
    GRU(hidden_size, input_shape=(301, input_size), return_sequences=True),
    GRU(hidden_size, return_sequences=True),
    GRU(hidden_size, return_sequences=False),
    Dense(hidden_size, input_shape=(hidden_size,), activation='relu'),
    Dense(hidden_size, input_shape=(hidden_size,), activation='relu'),
    Dense(num_classes, activation='sigmoid')
])

# Loss-Funktion, Optimizer
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])

history = model.fit(X_train, y_train,epochs= num_epochs, batch_size= batch_size)

# Plotten die Veränderung der Loss abhängig von Epoch.
plt.plot(history.history['loss'], label='Trainingsverlust')
plt.xlabel('Epochen')
plt.ylabel('Verlust')
plt.title('Verlust während des Trainings')
plt.legend()
plt.show()

plt.plot(history.history['accuracy'], label='Trainingsgenauigkeit')
#plt.plot(history.history['val_accuracy'], label='Validierungsgenauigkeit')
plt.xlabel('Epochen')
plt.ylabel('Accuracy')
plt.title('Genauigkeit während des Trainings')
plt.legend()
plt.show()

result = model.evaluate(X_train, y_train)
loss, accuracy = result  # Hier wird das Tupel aufgelöst
print(f"Test Loss: {loss}, Test Accuracy: {accuracy}")

# Vorhersage machen. Das sind die Outputs für die Vorhersage von X_test.
binäre_vorhersage = (model.predict(X_test) > threshold).astype(int)
class_labels = np.where(binäre_vorhersage == 1, "Gesund", "Krank")
print(class_labels)

"""Nach der Vorhersage, ermittelt wird wie Präzise das Neuronale Netzwerk den Output vorhergesagt hat. Dazu bedienen wir uns unterschiedliche Metriken, wie:


1.   Accuracy
2.   Precision
3.   Recall
4.   F1-Score

Das Problem ist jedoch, dass wir keine Sammlung von y_test haben sondern nur eine einzelne Vorhersage. Damit können diese unterschiedlichen Metriken nicht verwendet werden.
"""

# Berechne die Genauigkeit
accuracy = accuracy_score(y_test, binäre_vorhersage)
print("Genauigkeit auf Testdaten:", accuracy)

# Berechne Precision, Recall und F1-Score
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, binäre_vorhersage, average='binary')

print("Precision:", precision)
print("Recall:", recall)
print("F1-Score:", f1_score)

# Vorhersage Plotten!!!
plt.scatter(X_test[:, 0], X_test[:, 1], c=binäre_vorhersage, cmap='viridis', label=class_labels)
plt.xlabel('Amplitude')
plt.ylabel('Frequenz')
plt.title('Binary Classification')
#plt.legend(["Gesund", "Krank"])
plt.show()

from google.colab import drive
drive.mount('/content/drive')